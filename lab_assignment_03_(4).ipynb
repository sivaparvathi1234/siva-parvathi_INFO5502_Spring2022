{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sivaparvathi1234/siva-parvathi_INFO5502_Spring2022/blob/main/lab_assignment_03_(4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdB9Ck_yr7yV"
      },
      "source": [
        "## The third Lab-assignment (02/10/2022, 50 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lci1qPxr7yd"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40uJsK-Qr7ye"
      },
      "source": [
        "Question 1 (10 points). Fomulate your domain problem: Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ81qNzkr7yf"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "\n",
        "Domain Problem: \n",
        ". My domain problem is to get the prices of a product from shopping website.\n",
        "\n",
        "Research question:\n",
        ". to get the prices in the product, did a research on the vary of prices of that particular product.\n",
        "\n",
        "\n",
        "Data Required to answer the questions:\n",
        "The following are the attributes of the required data to answer the research question\n",
        ". product details\n",
        ". product with the class of particular attribute.\n",
        "\n",
        "\n",
        " i took the 1000 samples from the shopping website  the following link: \"https://www.flipkart.com/mens-footwear/sports-shoes/pr?sid=osp,cil,1cu&otracker=nmenu_sub_Men_0_Sports%20Shoes\"\n",
        "\n",
        "\n",
        "Steps for collecting and saving the data:\n",
        ". We need to use web scraping technique to get the data from that particular website.\n",
        ". imported BeautifulSoup under bs4 package is a library used to parse HTML & XML\n",
        ". There are 23 pages of products.\n",
        ". We parse through each page and go to the products price details to get the prices of that particular product.\n",
        ". We will get the price from the product homepage.\n",
        ". We parse the Segment Body-> Paragraph elements in the html code and then store the text data in a json format.\n",
        ".\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0dSyB4Yr7yh"
      },
      "source": [
        "Question 2 (10 points). Collect your data to answer the research problem: Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH67ntI4r7yi",
        "outputId": "ff0205ca-b85e-48a8-998f-98bac3a47532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "// Page 1 //\n",
            "45\n",
            "// Page 2 //\n",
            "90\n",
            "// Page 3 //\n",
            "135\n",
            "// Page 4 //\n",
            "180\n",
            "// Page 5 //\n",
            "225\n",
            "// Page 6 //\n",
            "270\n",
            "// Page 7 //\n",
            "315\n",
            "// Page 8 //\n",
            "360\n",
            "// Page 9 //\n",
            "405\n",
            "// Page 10 //\n",
            "450\n",
            "// Page 11 //\n",
            "495\n",
            "// Page 12 //\n",
            "540\n",
            "// Page 13 //\n",
            "585\n",
            "// Page 14 //\n",
            "630\n",
            "// Page 15 //\n",
            "675\n",
            "// Page 16 //\n",
            "720\n",
            "// Page 17 //\n",
            "765\n",
            "// Page 18 //\n",
            "810\n",
            "// Page 19 //\n",
            "855\n",
            "// Page 20 //\n",
            "900\n",
            "// Page 21 //\n",
            "945\n",
            "// Page 22 //\n",
            "990\n",
            "// Page 23 //\n",
            "1000\n",
            "['₹1,529', '₹3,959', '₹249', '₹219', '₹499', '₹471', '₹449', '₹499', '₹499', '₹1,047', '₹1,149', '₹398', '₹299', '₹449', '₹598', '₹259', '₹499', '₹1,611', '₹249', '₹299', '₹999', '₹1,049', '₹399', '₹259', '₹584', '₹241', '₹699', '₹1,449', '₹598', '₹574', '₹299', '₹749', '₹249', '₹359', '₹749', '₹259', '₹1,449', '₹749', '₹259', '₹449', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,529', '₹3,959', '₹249', '₹219', '₹499', '₹471', '₹449', '₹499', '₹499', '₹1,047', '₹1,149', '₹398', '₹299', '₹449', '₹598', '₹259', '₹1,049', '₹499', '₹249', '₹299', '₹1,611', '₹999', '₹399', '₹259', '₹584', '₹241', '₹699', '₹1,449', '₹598', '₹574', '₹299', '₹749', '₹249', '₹359', '₹749', '₹259', '₹1,449', '₹2,279', '₹259', '₹449', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,519', '₹471', '₹249', '₹219', '₹499', '₹1,518', '₹449', '₹499', '₹499', '₹1,047', '₹1,149', '₹398', '₹299', '₹449', '₹598', '₹259', '₹3,959', '₹1,049', '₹249', '₹299', '₹499', '₹1,611', '₹399', '₹259', '₹584', '₹241', '₹999', '₹1,047', '₹598', '₹574', '₹699', '₹1,449', '₹249', '₹359', '₹749', '₹259', '₹299', '₹2,536', '₹259', '₹449', '₹471', '₹259', '₹299', '₹2,536', '₹598', '₹1,519', '₹499', '₹249', '₹219', '₹499', '₹331', '₹449', '₹499', '₹499', '₹299', '₹3,959', '₹398', '₹449', '₹1,047', '₹598', '₹259', '₹1,299', '₹1,149', '₹249', '₹299', '₹999', '₹1,611', '₹399', '₹259', '₹584', '₹241', '₹1,049', '₹471', '₹598', '₹574', '₹699', '₹299', '₹249', '₹359', '₹749', '₹259', '₹749', '₹1,449', '₹259', '₹449', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,519', '₹471', '₹249', '₹219', '₹499', '₹1,518', '₹449', '₹499', '₹499', '₹1,047', '₹1,149', '₹398', '₹299', '₹449', '₹598', '₹259', '₹3,959', '₹499', '₹249', '₹299', '₹999', '₹1,049', '₹399', '₹259', '₹584', '₹241', '₹1,611', '₹1,047', '₹598', '₹574', '₹699', '₹1,449', '₹249', '₹359', '₹749', '₹259', '₹299', '₹2,536', '₹259', '₹449', '₹471', '₹259', '₹299', '₹2,536', '₹598', '₹1,519', '₹3,959', '₹249', '₹219', '₹499', '₹499', '₹449', '₹499', '₹499', '₹299', '₹449', '₹331', '₹1,047', '₹598', '₹259', '₹398', '₹249', '₹299', '₹399', '₹1,299', '₹259', '₹1,149', '₹584', '₹241', '₹598', '₹574', '₹249', '₹1,049', '₹359', '₹1,611', '₹749', '₹259', '₹259', '₹449', '₹249', '₹999', '₹584', '₹1,402', '₹499', '₹471', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,529', '₹3,959', '₹249', '₹219', '₹499', '₹471', '₹449', '₹499', '₹499', '₹1,047', '₹1,149', '₹398', '₹299', '₹449', '₹598', '₹259', '₹499', '₹1,611', '₹249', '₹299', '₹999', '₹1,049', '₹399', '₹259', '₹584', '₹241', '₹699', '₹1,449', '₹598', '₹574', '₹299', '₹749', '₹249', '₹359', '₹749', '₹259', '₹1,449', '₹749', '₹259', '₹449', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,529', '₹3,959', '₹249', '₹219', '₹499', '₹499', '₹449', '₹499', '₹499', '₹1,047', '₹299', '₹471', '₹449', '₹598', '₹259', '₹1,149', '₹249', '₹299', '₹399', '₹398', '₹259', '₹499', '₹584', '₹241', '₹598', '₹574', '₹249', '₹1,611', '₹359', '₹999', '₹749', '₹259', '₹259', '₹449', '₹249', '₹1,049', '₹584', '₹1,402', '₹499', '₹699', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,519', '₹3,959', '₹249', '₹219', '₹499', '₹499', '₹449', '₹499', '₹499', '₹299', '₹331', '₹398', '₹449', '₹1,047', '₹598', '₹259', '₹1,299', '₹1,149', '₹249', '₹299', '₹1,049', '₹1,611', '₹399', '₹259', '₹584', '₹241', '₹999', '₹471', '₹598', '₹574', '₹749', '₹699', '₹249', '₹359', '₹749', '₹259', '₹1,449', '₹649', '₹259', '₹449', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,529', '₹3,959', '₹249', '₹219', '₹499', '₹471', '₹449', '₹499', '₹499', '₹1,047', '₹1,149', '₹398', '₹299', '₹449', '₹598', '₹259', '₹1,049', '₹499', '₹249', '₹299', '₹1,611', '₹999', '₹399', '₹259', '₹584', '₹241', '₹699', '₹1,449', '₹598', '₹574', '₹299', '₹749', '₹249', '₹359', '₹749', '₹259', '₹1,449', '₹2,279', '₹259', '₹449', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,529', '₹3,959', '₹249', '₹219', '₹499', '₹471', '₹449', '₹499', '₹499', '₹1,047', '₹1,149', '₹398', '₹299', '₹449', '₹598', '₹259', '₹1,049', '₹499', '₹249', '₹299', '₹1,611', '₹999', '₹399', '₹259', '₹584', '₹241', '₹699', '₹1,449', '₹598', '₹574', '₹299', '₹749', '₹249', '₹359', '₹749', '₹259', '₹1,449', '₹2,279', '₹259', '₹449', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,519', '₹3,959', '₹249', '₹219', '₹499', '₹331', '₹449', '₹499', '₹499', '₹299', '₹499', '₹499', '₹449', '₹1,047', '₹598', '₹259', '₹1,149', '₹1,299', '₹249', '₹299', '₹398', '₹1,049', '₹399', '₹259', '₹584', '₹241', '₹999', '₹1,611', '₹598', '₹574', '₹471', '₹699', '₹249', '₹359', '₹749', '₹259', '₹749', '₹649', '₹259', '₹449', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,519', '₹471', '₹249', '₹219', '₹499', '₹499', '₹449', '₹499', '₹499', '₹1,047', '₹1,518', '₹1,149', '₹299', '₹449', '₹598', '₹259', '₹398', '₹3,959', '₹249', '₹299', '₹1,049', '₹499', '₹399', '₹259', '₹584', '₹241', '₹1,611', '₹999', '₹598', '₹574', '₹1,047', '₹699', '₹249', '₹359', '₹749', '₹259', '₹1,449', '₹299', '₹259', '₹449', '₹471', '₹259', '₹299', '₹598', '₹259', '₹1,529', '₹3,959', '₹249', '₹219', '₹499', '₹471', '₹449', '₹499', '₹499', '₹1,047', '₹1,149', '₹398', '₹299', '₹449', '₹598', '₹259', '₹1,049', '₹499', '₹249', '₹299', '₹1,611', '₹999', '₹399', '₹259', '₹584', '₹241', '₹699', '₹1,449', '₹598', '₹574', '₹299', '₹749', '₹249', '₹359', '₹749', '₹259', '₹1,449', '₹2,279', '₹259', '₹449', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,529', '₹3,959', '₹249', '₹219', '₹499', '₹471', '₹449', '₹499', '₹499', '₹1,047', '₹1,149', '₹398', '₹299', '₹449', '₹598', '₹259', '₹499', '₹1,611', '₹249', '₹299', '₹999', '₹1,049', '₹399', '₹259', '₹584', '₹241', '₹699', '₹1,449', '₹598', '₹574', '₹299', '₹749', '₹249', '₹359', '₹749', '₹259', '₹1,449', '₹749', '₹259', '₹449', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,529', '₹3,959', '₹249', '₹219', '₹499', '₹471', '₹449', '₹499', '₹499', '₹1,047', '₹1,149', '₹398', '₹299', '₹449', '₹598', '₹259', '₹499', '₹1,611', '₹249', '₹299', '₹999', '₹1,049', '₹399', '₹259', '₹584', '₹241', '₹699', '₹1,449', '₹598', '₹574', '₹299', '₹749', '₹249', '₹359', '₹749', '₹259', '₹1,449', '₹749', '₹259', '₹449', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,519', '₹331', '₹249', '₹219', '₹499', '₹3,959', '₹449', '₹499', '₹499', '₹299', '₹471', '₹1,149', '₹449', '₹1,047', '₹598', '₹259', '₹398', '₹1,299', '₹249', '₹299', '₹499', '₹1,611', '₹399', '₹259', '₹584', '₹241', '₹999', '₹1,049', '₹598', '₹574', '₹1,047', '₹699', '₹249', '₹359', '₹749', '₹259', '₹1,449', '₹299', '₹259', '₹449', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,519', '₹471', '₹249', '₹219', '₹499', '₹499', '₹449', '₹499', '₹499', '₹1,047', '₹1,518', '₹1,149', '₹299', '₹449', '₹598', '₹259', '₹398', '₹3,959', '₹249', '₹299', '₹499', '₹999', '₹399', '₹259', '₹584', '₹241', '₹1,049', '₹1,611', '₹598', '₹574', '₹1,047', '₹699', '₹249', '₹359', '₹749', '₹259', '₹1,449', '₹299', '₹259', '₹449', '₹471', '₹259', '₹299', '₹598', '₹259', '₹1,519', '₹3,959', '₹249', '₹219', '₹499', '₹331', '₹449', '₹499', '₹499', '₹299', '₹499', '₹1,149', '₹449', '₹1,047', '₹598', '₹259', '₹1,299', '₹398', '₹249', '₹299', '₹1,049', '₹999', '₹399', '₹259', '₹584', '₹241', '₹1,611', '₹471', '₹598', '₹574', '₹699', '₹749', '₹249', '₹359', '₹749', '₹259', '₹649', '₹1,449', '₹259', '₹449', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,519', '₹3,959', '₹249', '₹219', '₹499', '₹331', '₹449', '₹499', '₹499', '₹299', '₹499', '₹1,149', '₹449', '₹1,047', '₹598', '₹259', '₹1,299', '₹398', '₹249', '₹299', '₹1,049', '₹999', '₹399', '₹259', '₹584', '₹241', '₹1,611', '₹471', '₹598', '₹574', '₹699', '₹749', '₹249', '₹359', '₹749', '₹259', '₹649', '₹1,449', '₹259', '₹449', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,519', '₹331', '₹249', '₹219', '₹499', '₹3,959', '₹449', '₹499', '₹499', '₹299', '₹499', '₹471', '₹449', '₹1,047', '₹598', '₹259', '₹1,149', '₹398', '₹249', '₹299', '₹1,299', '₹499', '₹399', '₹259', '₹584', '₹241', '₹1,611', '₹999', '₹598', '₹574', '₹1,049', '₹1,047', '₹249', '₹359', '₹749', '₹259', '₹699', '₹1,449', '₹259', '₹449', '₹259', '₹299', '₹1,611', '₹598', '₹259', '₹1,519', '₹471', '₹249', '₹219', '₹499', '₹1,518', '₹449', '₹499', '₹499', '₹1,047', '₹1,149', '₹3,959', '₹299', '₹449', '₹598', '₹259', '₹1,049', '₹999', '₹249', '₹299', '₹1,611', '₹1,047', '₹399', '₹259', '₹584', '₹241', '₹398', '₹499', '₹598', '₹574', '₹699', '₹1,449', '₹249', '₹359', '₹749', '₹259', '₹749', '₹299', '₹259', '₹449', '₹471', '₹259', '₹299', '₹598', '₹259', '₹1,529', '₹3,959', '₹249', '₹219', '₹499', '₹471', '₹449', '₹499', '₹499', '₹1,047']\n"
          ]
        }
      ],
      "source": [
        "#  importing BeautifulSoup under bs4 package is a library used to parse HTML & XML\n",
        "from bs4 import BeautifulSoup\n",
        "# urllib module is the URL handling module for python\n",
        "import urllib\n",
        "#It helps to define functions and classes, these  help in opening URLs\n",
        "from urllib.request import Request, urlopen\n",
        "from urllib.error import HTTPError\n",
        "# to get the file in json format\n",
        "import json\n",
        "import re\n",
        "\n",
        "total_count = 0\n",
        "count = 0\n",
        "\n",
        "prices = []\n",
        "main_url = \"https://www.flipkart.com/mens-footwear/sports-shoes/pr?sid=osp,cil,1cu&otracker=nmenu_sub_Men_0_Sports%20Shoes\"\n",
        "for page_num in range(1, 100):\n",
        "    # we create the data soup of the main url page html elements.\n",
        "    link1 = Request(main_url.format(page_num), headers={'User-Agent': 'Mozilla/5.0'})\n",
        "    url1 = urllib.request.urlopen(link1)\n",
        "    data1 = url1.read()\n",
        "    data1_soup = BeautifulSoup(data1)\n",
        "\n",
        "    print(\"// Page {} //\".format(page_num))\n",
        "    # we will iterate through pages of the  search results till we get 1000 records\n",
        "    for narrator_link in data1_soup.find_all('div', attrs = {'class': \"_30jeq3\"}):\n",
        "        prices.append(narrator_link.text)\n",
        "        count = count + 1\n",
        "        if count == 1000:\n",
        "            break          \n",
        "    print(count)\n",
        "    if count == 1000:\n",
        "        break\n",
        "    \n",
        "print(prices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qENh8E_Hr7yo"
      },
      "source": [
        "Question 3 (10 points). Understand the data quality: Search a second hand dataset (any dataset) from kaggle or other websites. Describe the data quality problem of the dataset and explain your strtegy to clean the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLrqN3pqr7yp"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "'''\n",
        "\n",
        "Please write you answer here:\n",
        "\n",
        "Dataset:\n",
        ". Link: https://www.kaggle.com/shantanudhakadd/email-spam-detection-dataset-classification\n",
        ". There are 4 data columns in the dataset.\n",
        "   1) first column is to check whether the email is spam or not spam.\n",
        "   2)second column is to check the content of the mail.\n",
        ". The target column  has  2 classes  like Spam or Not Spam and content of the mail.\n",
        "\n",
        " In the dataset, data from the email is classified to 5 categeries like valid, mismatched,missing,unique, most common. Based on the percentage, we are able to check whether the email is spam or not.\n",
        "\n",
        "Strategies to clean the data :\n",
        "1. we will check the most common emails and start segrigating those mials first.\n",
        "2.we have to start brushing the active lists from the data.\n",
        "3. Remove or start merging the duplicates from your mails.\n",
        "4. we have to remove the spam email addresses.\n",
        "5.check the missing fields\n",
        "6. check the duplicate data \n",
        "7. check the  invalid formatting\n",
        "using deep learning model , we can check whether the email is spam or not spam.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4XOxO32r7yq"
      },
      "source": [
        "Question 4 (20 points). Data cleaning: There are two datasets TwADR-L (from Twitter) and AskAPatient (Link: https://zenodo.org/record/55013#.YgU2NN-ZO4T) for medical concept\n",
        "normalization. However, the two datasets have serious data quality problems. Please read the introduction of the datasets and clean the two datasets by following the steps in the statement.\n",
        "\n",
        "In the original dataset, the TwADR-L had 48,057 training, 1,256 validation and 1,427 test examples. The test set (all\n",
        "test samples from 10 folds combined) consists of 765 unique phrases and 273 unique classes (medical concepts). The AskAPatient dataset contained 156,652 training, 7,926 validation, and 8,662 test examples. The entire test set (all test samples\n",
        "from 10 folds combined) consists of 3,749 unique phrases and 1,035 unique classes (medical concepts). The authors\n",
        "randomly split each dataset into ten equal folds, ran 10-fold cross validation and reported the accuracy averaged across the\n",
        "ten folds. \n",
        "\n",
        "We found that, in the original data set, many phrase-label pairs appeared multiple times within the same training data file\n",
        "and also across the training and test data sets in the same fold. In the AskAPatient data set, on average 35.82% of the test data overlapped with training data in the same fold. In the Twitter (TwADR-L) dataset, on average 8.62% of the test set had an overlap with the training data in the same fold. Having a large overlap between the training and the test data can potentially\n",
        "introduce bias in the model and contribute to high accuracy. It is not unlikely that the high model performance reported in the original paper may be triggered by the the large overlap between the training and test sets.\n",
        "\n",
        "Therefore to remove the bias, we further cleaned and recreated the training, validation, and test sets such that each\n",
        "phrase-label pair appears only once in the entire dataset (either in training, validation or test set).\n",
        "\n",
        "(1) First, we combined all examples in training, validation and test data from the original data set and then removed all\n",
        "duplicate phrase-label pairs (examples that have the same phrase and label pair and appear more than once in training/validation/test datasets). Table II shows the statistics of the new dataset (after removing duplicates). The Twitter data set had 3,157 unique phrase-label pairs and 2,220 unique labels (medical concepts) while 173 phrases had multiple labels (i.e., they were assigned to more than one label). Many concepts had only one example, and the concept that had the most number\n",
        "of examples had 36 phrases. On average, each concept had 1.42 examples. The AskAPatient data set had 4,496 unique phrase-label pairs, 1,036 unique labels while 26 phrases had multiple labels. Table III shows examples of phrases that had multiple labels. For example, ‘mad’ can be mapped to ‘anger’ or ‘rage’ and ‘sore’ can be mapped to ‘pain’ or ‘myalgia’.\n",
        "\n",
        "(2) Second, we remove all concepts that had less than five examples. The statistics of the final data are shown in Table IV.\n",
        "\n",
        "(3) Third, we divide all examples without multiple labels into random 10 folds such that each unique phrase-label pair\n",
        "appears once in one of the 10 test sets. We add the pairs with multiple labels into the training data. This final 10-folds\n",
        "dataset is used in all our experiments.\n",
        "\n",
        "(The original paper can be download on canvas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "pMgYgOv6r7ys",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "ad2b42c0-0f56-4415-f34a-a1743b2821ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/sample_data/datasets.zip\n",
            "replace datasets/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-948f96b4-b45d-4da6-8cf5-4b89fc4dcd49\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TwADR-L</th>\n",
              "      <th>AskAPatient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Unique_phrases</th>\n",
              "      <td>2944</td>\n",
              "      <td>4470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique_labels</th>\n",
              "      <td>2220</td>\n",
              "      <td>1038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique_phrase_label_pairs</th>\n",
              "      <td>3157</td>\n",
              "      <td>4507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phrases with multiple labels</th>\n",
              "      <td>173</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Min examples per label</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max examples per label</th>\n",
              "      <td>36</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Avg examples per label</th>\n",
              "      <td>1.42</td>\n",
              "      <td>4.34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-948f96b4-b45d-4da6-8cf5-4b89fc4dcd49')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-948f96b4-b45d-4da6-8cf5-4b89fc4dcd49 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-948f96b4-b45d-4da6-8cf5-4b89fc4dcd49');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             TwADR-L AskAPatient\n",
              "Unique_phrases                  2944        4470\n",
              "Unique_labels                   2220        1038\n",
              "Unique_phrase_label_pairs       3157        4507\n",
              "Phrases with multiple labels     173          35\n",
              "Min examples per label             1           1\n",
              "Max examples per label            36         141\n",
              "Avg examples per label          1.42        4.34"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "# 1)\n",
        "import glob\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "import csv\n",
        "!unzip /content/sample_data/datasets.zip\n",
        "result_df =  pd.DataFrame()\n",
        "for dataset in ['TwADR-L', 'AskAPatient']:\n",
        "    result = {}\n",
        "    df = pd.DataFrame()\n",
        "    for filepath in glob.glob('/content/datasets/{}/*.txt'.format(dataset)):\n",
        "        data = pd.read_csv(filepath, sep = \"\\t\", header = None, encoding= 'unicode_escape')\n",
        "        df = df.append(data)\n",
        "        \n",
        "    df = df.reset_index(drop=True)\n",
        "    df['phrase_label'] = df[1] + \" \" + df[2]\n",
        "    df.columns = ['id', 'labels', 'phrases', 'phrase-label']\n",
        "    df = df.astype({\"id\": str})\n",
        "       \n",
        "    for columns in df.columns:\n",
        "        df[columns] = df[columns].str.lower() \n",
        "\n",
        "    # dropping duplicates\n",
        "    df = df.drop_duplicates('phrase-label')\n",
        "\n",
        "    # storing results of the table in dictionary\n",
        "    result['Unique_phrases'] = str(len(df['phrases'].unique()))\n",
        "    result['Unique_labels'] = str(len(df['labels'].unique()))\n",
        "    result['Unique_phrase_label_pairs'] = str(df.shape[0])\n",
        "    df1 = pd.DataFrame(df['phrases'].value_counts())\n",
        "    result['Phrases with multiple labels'] = str(df1[df1['phrases'] > 1].shape[0])\n",
        "    result['Min examples per label'] = str(df['labels'].value_counts().values.min())\n",
        "    result['Max examples per label'] = str(df['labels'].value_counts().values.max())\n",
        "    result['Avg examples per label'] = round(df['labels'].value_counts().mean(),2)\n",
        "    result_df = result_df.append(result, ignore_index=True)\n",
        "\n",
        "\n",
        "result_df = result_df.T\n",
        "# result_df.iloc[0:6].astype(int)\n",
        "    \n",
        "result_df.columns = ['TwADR-L', 'AskAPatient']\n",
        "\n",
        "result_df\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "import csv\n",
        "!unzip /content/sample_data/datasets.zip\n",
        "result_df = pd.DataFrame()\n",
        "# we iterate through both datasets \n",
        "for dataset in ['TwADR-L', 'AskAPatient']:\n",
        "    df = pd.DataFrame()\n",
        "    result = {}\n",
        "    for filepath in glob.glob('/content/datasets/{}/*.txt'.format(dataset)):\n",
        "        #print(filepath)\n",
        "        data = pd.read_csv(filepath, sep = \"\\t\", header = None, encoding= 'unicode_escape')\n",
        "        df = df.append(data)\n",
        "    # we create combined dataframe by combining Each dataset text files.\n",
        "    df = df.reset_index(drop=True)\n",
        "    df['phrase_label'] = df[1] + \" \" + df[2]\n",
        "    df.columns = ['id', 'labels', 'phrases', 'phrase-label']\n",
        "    #print(df.shape)\n",
        "    df = df.astype({\"id\": str})\n",
        "    # converting to lower case\n",
        "    for columns in df.columns:\n",
        "        df[columns] = df[columns].str.lower() \n",
        "\n",
        "    # we drop duplicates that are phrase-label pairs... \n",
        "    df = df.drop_duplicates('phrase-label')\n",
        "\n",
        "    index_list = []\n",
        "    for i in range(df.shape[0]):\n",
        "        if df['labels'].value_counts()[df.iloc[i]['labels']] < 5:\n",
        "            index_list.append(i)\n",
        "\n",
        "    # we drop the labels that have less than count of 5.\n",
        "    df.drop(df.index[index_list], inplace=True)\n",
        "    result = {}\n",
        "\n",
        "    if dataset == 'TwADR-L':\n",
        "      Twt_df = df\n",
        "    else:\n",
        "      Ask_df = df\n",
        " \n",
        "    # storing results of the table in dictionary\n",
        "    result['Unique_phrases'] = str(len(df['phrases'].unique()))\n",
        "    result['Unique_labels'] = str(len(df['labels'].unique()))\n",
        "    result['Unique_phrase_label_pairs'] = str(df.shape[0])\n",
        "    df1 = pd.DataFrame(df['phrases'].value_counts())\n",
        "    result['Phrases with multiple labels'] = str(df1[df1['phrases'] > 1].shape[0])\n",
        "    result['Min examples per label'] = str(df['labels'].value_counts().values.min())\n",
        "    result['Max examples per label'] = str(df['labels'].value_counts().values.max())\n",
        "    result['Avg examples per label'] = round(df['labels'].value_counts().mean(), 2)\n",
        "    # appending dictinary to dataframe\n",
        "    result_df = result_df.append(result, ignore_index=True)\n",
        "\n",
        "result_df = result_df.T\n",
        "result_df.columns = ['TwADR-L', 'AskAPatient']\n",
        "\n",
        "\n",
        "result_df"
      ],
      "metadata": {
        "id": "JDrGU7ebnbIu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "54322075-b0b6-471a-d1e7-276d7a2b2f6b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6b0c963c-9db0-4a09-bd7c-626cb0ca1f13\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TwADR-L</th>\n",
              "      <th>AskAPatient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Unique_phrases</th>\n",
              "      <td>616</td>\n",
              "      <td>2665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique_labels</th>\n",
              "      <td>76</td>\n",
              "      <td>233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unique_phrase_label_pairs</th>\n",
              "      <td>721</td>\n",
              "      <td>2686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Phrases with multiple labels</th>\n",
              "      <td>87</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Min examples per label</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max examples per label</th>\n",
              "      <td>36</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Avg examples per label</th>\n",
              "      <td>9.49</td>\n",
              "      <td>11.53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b0c963c-9db0-4a09-bd7c-626cb0ca1f13')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b0c963c-9db0-4a09-bd7c-626cb0ca1f13 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b0c963c-9db0-4a09-bd7c-626cb0ca1f13');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             TwADR-L AskAPatient\n",
              "Unique_phrases                   616        2665\n",
              "Unique_labels                     76         233\n",
              "Unique_phrase_label_pairs        721        2686\n",
              "Phrases with multiple labels      87          19\n",
              "Min examples per label             5           5\n",
              "Max examples per label            36         141\n",
              "Avg examples per label          9.49       11.53"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "lab_assignment_03 (4).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}